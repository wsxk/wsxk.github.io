---
layout: post
tags: [AI]
title: "AI agent学习2： 智能体经典范式"
author: wsxk
date: 2025-01-15
comments: true
---

- [1. ReAct](#1-react)
  - [1.1 ReAct demo](#11-react-demo)
  - [1.2 ReAct 优点与局限性](#12-react-优点与局限性)
- [2. Plan-and-Solve](#2-plan-and-solve)
- [references](#references)


# 1. ReAct<br>
**ReAct的巧妙之处是，它认识到思考与行动是相辅相成的。**思考指导行动，而行动的结果又反过来修正思考。为此，ReAct范式通过一种特殊的提示工程来引导模型，使其每一步的输出都遵循一个固定的轨迹：<br>
```
Thought (思考)： 这是智能体的“内心独白”。它会分析当前情况、分解任务、制定下一步计划，或者反思上一步的结果。
Action (行动)： 这是智能体决定采取的具体动作，通常是调用一个外部工具，例如 Search['华为最新款手机']。
Observation (观察)： 这是执行Action后从外部工具返回的结果，例如搜索结果的摘要或API的返回值。
```
智能体将不断重复这个 Thought -> Action -> Observation 的循环，将新的观察结果追加到历史记录中，形成一个不断增长的上下文，直到它在Thought中认为已经找到了最终答案，然后输出结果。**这个过程形成了一个强大的协同效应：推理使得行动更具目的性，而行动则为推理提供了事实依据。**<br>
## 1.1 ReAct demo<br>
demo:<br>
```python
import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List,Dict

#加载环境变量 .env文件
load_dotenv()

class HelloAgentsLLM:
    """
    为本书 "Hello Agents" 定制的LLM客户端。
    它用于调用任何兼容OpenAI接口的服务，并默认使用流式响应。
    """
    def __init__(self, model: str=None, apiKey: str=None, baseUrl: str=None,timeout: int=None):
        """
        初始化客户端。优先使用传入参数，如果未提供，则从环境变量加载。
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT",60))
        
        if not all([self.model,apiKey,baseUrl,timeout]):
            raise ValueError("模型ID、API密钥和服务地址必须被提供或在.env文件中定义。")

        self.client = OpenAI(api_key=apiKey,base_url=baseUrl,timeout=timeout)

    def think(self,messages: List[Dict[str, str]],temperature: float=0) -> str:
        """
        调用大语言模型进行思考，并返回其响应。
        """
        print(f"🧠 正在调用 {self.model} 模型...")
        try:
            response = self.client.chat.completions.create(model=self.model,messages=messages,temperature=temperature,stream=True)
            # 处理流式响应
            print("✅ 大语言模型响应成功:")
            collect_content=[]
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content,end='',flush=True)
                collect_content.append(content)
            print() # 在流式输出结束后换行
            return "".join(collect_content)
        
        except Exception as e:
            print(f"❌ 调用LLM API时发生错误: {e}")
            return None
        
from serpapi import SerpApiClient
def search(query: str) -> str:
    """
    一个基于SerpApi的实战网页搜索引擎工具。
    它会智能地解析搜索结果，优先返回直接答案或知识图谱信息。
    """
    print(f"🔍 正在执行 [SerpApi] 网页搜索: {query}")
    try:
        api_key = os.getenv("SERPAPI_API_KEY")
        if not api_key:
            return "错误:SERPAPI_API_KEY 未在 .env 文件中配置。"

        params = {
            "engine": "google",
            "q": query,
            "api_key": api_key,
            "gl": "cn", #国家代码
            "hl": "zh-cn", #语言代码
        }
        client = SerpApiClient(params)
        results = client.get_dict()

        # 智能解析:优先寻找最直接的答案
        if "answer_box_list" in results:    # answer_box（Google的答案摘要框）
            return "\n".join(results["answer_box_list"])
        if "answer_box" in results and "answer" in results["answer_box"]:
            return results["answer_box"]["answer"]
        if "knowledge_graph" in results and "description" in results["knowledge_graph"]:  # knowledge_graph（知识图谱）
            return results["knowledge_graph"]["description"]
        if "organic_results" in results and results["organic_results"]:
            # 如果没有直接答案，则返回前三个有机结果的摘要
            snippets = [
                f"[{i+1}] {res.get('title', '')}\n{res.get('snippet', '')}"
                for i, res in enumerate(results["organic_results"][:3])
            ]
            return "\n\n".join(snippets)
        
        return f"对不起，没有找到关于 '{query}' 的信息。"
    except Exception as e:
        return f"搜索时发生错误: {e}"
    
from typing import Dict, Any
class ToolExecutor:
    """
    一个工具执行器，负责管理和执行工具。
    """
    def __init__(self):
        self.tools: Dict[str, Dict[str, Any]] = {}
    def registerTools(self,name: str,description: str,func: callable):
        """
        向工具箱中注册一个新工具。
        """
        if name in self.tools:
            print(f"警告:工具 '{name}' 已存在，将被覆盖。")
        self.tools[name] = {"description":description,"func":func}
        print(f"工具 '{name}' 已注册。")
    
    def getTools(self,name: str)-> callable:
        """
        根据名称获取一个工具的执行函数。
        """
        return self.tools.get(name,{}).get("func")
    
    def getAvailableTools(self)->str:
        """
        获取所有可用工具的格式化描述字符串。
        """
        return "\n".join([
            f"- {name} : {info["description"]}"
            for name, info in self.tools.items()
        ])

# ReAct提示词模板
# 角色定义，工具清单，格式规约，动态上下文
REACT_PROMPT_TEMPLATE = """
请注意，你是一个有能力调用外部工具的智能助手。

可用工具如下:
{tools}

请严格按照以下格式进行回应:

Thought: 你的思考过程，用于分析问题、拆解任务和规划下一步
Action: 你决定采取的行动，必须是以下格式之一:
- `{{tool_name}}[{{tool_input}}]`:调用一个可用工具
- `Finish[最终答案]`:当你认为已经获得最终答案时。
- 当你收集到足够的信息，能够回答用户的最终问题时，你必须在Action:字段后使用 finish(answer="...")来输出最终答案。

现在，请开始解决以下问题：
Question: {question}
History: {history}
"""
import re
class ReActAgent:
    def __init__(self,llm_client: HelloAgentsLLM,tool_executor: ToolExecutor,max_steps: int=5):
        self.llm_client = llm_client
        self.tool_executor = tool_executor
        self.max_steps = max_steps
        self.history = []

    #（这些方法 是 ReActAgent类的一部分）
    def _parse_output(self,text: str):
        """解析LLM的输出，提取Thought和Action"""
        thought_match = re.search(r"Thought: (.*)",text) # .默认不匹配换行符
        action_match = re.search(r"Action: (.*)",text)
        thought = thought_match.group(1).strip() if thought_match else None # 0表示整个字串（包括Thought），1表示获取(.*)匹配到的内容
        action = action_match.group(1).strip() if action_match else None
        return thought, action

    def _parse_action(self,action_text: str):
        """解析Action字符串，提取工具名称和输入。"""
        match = re.match(r"(\w+)\[(.*)\]",action_text)
        if match:
            return match.group(1), match.group(2) # 1表示工具名(\w+), 2表示输入(.*)
        return None, None
    
    def run(self,question:str):
        """
        运行ReAct智能体来回答一个问题。
        """
        self.history = [] #每次运行时重置历史记录
        current_step= 0

        while current_step < self.max_steps:
            current_step += 1
            print(f"--- 第{current_step}步 ---")

            # 1. 格式化提示词
            tools_desc = self.tool_executor.getAvailableTools()
            history_str = "\n".join(self.history)
            prompt = REACT_PROMPT_TEMPLATE.format(
                tools=tools_desc,
                question=question,
                history=history_str
            )

            # 2. 调用LLM进行思考
            messages = [{"role":"user","content":prompt}]
            response_text = self.llm_client.think(messages=messages)

            if not response_text :
                print("错误:LLM未能返回有效响应")
                break
            # ...(后续的解析、执行、整合步骤)
            # 3. 解析LLM的输出
            thought,action = self._parse_output(response_text)

            if thought:
                print(f"思考: {thought}")
            
            if not action:
                print("警告，未能解析出有效的Action，流程中止。")
                break

            # 4. 执行action
            if action.startswith("Finish"):
                # 如果是Finish指令，提取最终答案并结束
                final_answer = re.match(r"Finish\[(.*)\]",action).group(1)
                print(f"最终答案: {final_answer}")
                return final_answer
            
            tool_name, tool_input = self._parse_action(action)
            if not tool_name or not tool_input:
                # ....处理无效Action格式 ....
                continue
            print(f"🎬 行动: {tool_name}[{tool_input}]")
            tool_function = self.tool_executor.getTools(tool_name)
            if not tool_function:
                observation = f"错误:未找到名为 '{tool_name}'的工具。"
            else:
                observation = tool_function(tool_input) # 调用真实工具。

            # 5. 将action本身和工具执行后的observation添加到历史记录中。
            # （这段逻辑紧随工具调用之后，在 while 循环的末尾）
            print(f"👀 观察: {observation}")
            # 将本轮的Action和observation添加到历史记录中
            self.history.append(f"Action: {action}")
            self.history.append(f"Observation: {observation}")

        # 循环结束
        print("已达到最大步数，流程中止。")
        return None


if __name__ == "__main__":
    llm = HelloAgentsLLM()
    tool_executor = ToolExecutor()
    search_desc = "一个搜索网页的引擎，当你需要回答关于时事、事实以及在你的知识库中找不到的信息时，应使用此工具"
    tool_executor.registerTools("Search",search_desc,search)
    agent = ReActAgent(llm_client=llm,tool_executor=tool_executor)
    question = "华为最新的手机是哪一款？它的主要卖点是什么？"
    agent.run(question)
```
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2025-9-25/20260102232408.png)

## 1.2 ReAct 优点与局限性<br>
```
（1）ReAct 的主要特点
1.1 高可解释性：ReAct 最大的优点之一就是透明。
通过 Thought 链，我们可以清晰地看到智能体每一步的“心路历程”——它为什么会选择这个工具，下一步又打算做什么。
这对于理解、信任和调试智能体的行为至关重要。

1.2 动态规划与纠错能力：与一次性生成完整计划的范式不同，ReAct 是“走一步，看一步”。
它根据每一步从外部世界获得的 Observation 来动态调整后续的 Thought 和 Action。
如果上一步的搜索结果不理想，它可以在下一步中修正搜索词，重新尝试。

1.3 工具协同能力：ReAct 范式天然地将大语言模型的推理能力与外部工具的执行能力结合起来。
LLM 负责运筹帷幄（规划和推理），工具负责解决具体问题（搜索、计算），二者协同工作，突破了单一 LLM 在知识时效性、计算准确性等方面的固有局限。


（2）ReAct 的固有局限性
2.1 对LLM自身能力的强依赖：ReAct 流程的成功与否，高度依赖于底层 LLM 的综合能力。
如果 LLM 的逻辑推理能力、指令遵循能力或格式化输出能力不足，就很容易在 Thought 环节产生错误的规划，或者在 Action 环节生成不符合格式的指令，导致整个流程中断。

2.2 执行效率问题：由于其循序渐进的特性，完成一个任务通常需要多次调用 LLM。
每一次调用都伴随着网络延迟和计算成本。
对于需要很多步骤的复杂任务，这种串行的“思考-行动”循环可能会导致较高的总耗时和费用。

2.3 提示词的脆弱性：整个机制的稳定运行建立在一个精心设计的提示词模板之上。
模板中的任何微小变动，甚至是用词的差异，都可能影响 LLM 的行为。
此外，并非所有模型都能持续稳定地遵循预设的格式，这增加了在实际应用中的不确定性。

2.4 可能陷入局部最优：步进式的决策模式意味着智能体缺乏一个全局的、长远的规划。
它可能会因为眼前的 Observation 而选择一个看似正确但长远来看并非最优的路径，甚至在某些情况下陷入“原地打转”的循环中。
```
**当遇到ReAct的问题时，调试可以从以下几点入手:**<br>
```
1. 检查完整的提示词：
在每次调用 LLM 之前，将最终格式化好的、包含所有历史记录的完整提示词打印出来。这是追溯 LLM 决策源头的最直接方式。

2. 分析原始输出：
当输出解析失败时（例如，正则表达式没有匹配到 Action），务必将 LLM 返回的原始、未经处理的文本打印出来。这能帮助你判断是 LLM 没有遵循格式，还是你的解析逻辑有误。

3. 验证工具的输入与输出：
检查智能体生成的 tool_input 是否是工具函数所期望的格式，同时也要确保工具返回的 observation 格式是智能体可以理解和处理的。

4. 调整提示词中的示例 (Few-shot Prompting)：
如果模型频繁出错，可以在提示词中加入一两个完整的“Thought-Action-Observation”成功案例，通过示例来引导模型更好地遵循你的指令。

5. 尝试不同的模型或参数：
更换一个能力更强的模型，或者调整 temperature 参数（通常设为0以保证输出的确定性），有时能直接解决问题。
```

# 2. Plan-and-Solve<br>
Plan-and-Solve Prompting 由 Lei Wang 在2023年提出。其核心动机是为了解决思维链在处理多步骤、复杂问题时容易“偏离轨道”的问题。<br>
与 ReAct 将思考和行动融合在每一步不同，Plan-and-Solve 将整个流程解耦为两个核心阶段，如下所示:<br>
```
1. 规划阶段 (Planning Phase)： 首先，智能体会接收用户的完整问题。
它的第一个任务不是直接去解决问题或调用工具，而是将问题分解，并制定出一个清晰、分步骤的行动计划。这个计划本身就是一次大语言模型的调用产物。

2. 执行阶段 (Solving Phase)： 在获得完整的计划后，智能体进入执行阶段。
它会严格按照计划中的步骤，逐一执行。
每一步的执行都可能是一次独立的 LLM 调用，或者是对上一步结果的加工处理，直到计划中的所有步骤都完成，最终得出答案。
```
这种“先谋后动”的策略，使得智能体在处理需要长远规划的复杂任务时，能够保持更高的目标一致性，避免在中间步骤中迷失方向。<br>


# references<br>
[https://datawhalechina.github.io/hello-agents/#/./chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA?id=_421-react-%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b](https://datawhalechina.github.io/hello-agents/#/./chapter4/%E7%AC%AC%E5%9B%9B%E7%AB%A0%20%E6%99%BA%E8%83%BD%E4%BD%93%E7%BB%8F%E5%85%B8%E8%8C%83%E5%BC%8F%E6%9E%84%E5%BB%BA?id=_421-react-%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%a8%8b)<br>


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-C22S5YSYL7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-C22S5YSYL7');
</script>