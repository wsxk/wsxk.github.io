---
layout: post
tags: [AI]
date: "2023-7-20"
title: "Image AI"
author: wsxk
comments: true
---

- [图像生成基本概念](#图像生成基本概念)
- [1. VAE(Variational Auto-encoder)](#1-vaevariational-auto-encoder)
- [2. Flow-based Generative Model ](#2-flow-based-generative-model-)
- [3. Diffusion Model](#3-diffusion-model)
  - [一、工作原理](#一工作原理)
  - [二、如何训练Noise Predicter](#二如何训练noise-predicter)
  - [三、实际训练步骤](#三实际训练步骤)
- [4. Generative Adversarial Network (GAN)](#4-generative-adversarial-network-gan)
- [Stable Diffusion](#stable-diffusion)
  - [一、 Text Encoder](#一-text-encoder)
  - [二、 Generation Model](#二-generation-model)
  - [三、 Decoder](#三-decoder)


## 图像生成基本概念<br>
先前也介绍过，图像生成使用的是`NAR(No-autoregressive)`<br>
因为`AR`太耗时了<br>
然而`NAR`也不是一点坏处都没有，最显著的问题就是，取样时各个像素点是不关联的，就会导致合成一个四不像的图片出来(<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720163730.png)
为了解决这个问题，通常的图像生成模型都加入了`Normal Distribution`来增加取样点的相似度<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720163908.png)
以下是当前图像生成模型的常用方法<br>

## 1. VAE(Variational Auto-encoder)<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720164304.png)

## 2. Flow-based Generative Model <br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720164408.png)

## 3. Diffusion Model<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720164459.png)
Diffusion Model的本质思想和米开朗基罗的一句话很像:`雕塑其实就在大理石里，我们只是去掉了一些不必要的成分罢了`<br>
Diffusion Model是现在很多stoa的框架使用的技术，所以着重学习它<br>
### 一、工作原理<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720164941.png)
实际上一个`Denoise`要做的事情，其实是生成一个噪音，然后在输入的图片中减去这个噪音而已<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720165117.png)
### 二、如何训练Noise Predicter<br>
下图可以比较直观的显示:<br>
在训练时，使用正常图片，然后随机添加噪音;**随机添加的噪音就是样本数据！**<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720165355.png)
当然，实际上是需要有文本输入的模型，如下图所示:<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720165618.png)
大致情况是: 
1. 文本-图像生成器根据文本t 生成图片p1；<br>
2. 对p做随机噪音处理1,2,...n次，保留第i次添加的噪音noise_i，以及最终的噪声图片p2<br>
3. 将p2和t和i喂入Noise Predicter，生成的噪音niose2_i与noise_i进行对比，修正误差<br>

### 三、实际训练步骤<br>
其实，实际上的`noise predictor`训练和推导过程和上述说的答题思路一致，但是**实际做法有差异**<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230721104026.png)
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230721104044.png)
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230721104109.png)
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230721104129.png)
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230721104200.png)

## 4. Generative Adversarial Network (GAN)<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720164525.png)


## Stable Diffusion<br>
这个最新最热的技术所用的流程如下图所示<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720170111.png)

### 一、 Text Encoder<br>
这个东西据当前最新最热实验证实，是很重要滴，图片画的好不好，很大程度取决于它，具体怎么造它，我也不知道<br>
衡量它的标准主要有2个`FID`（越小越好）和`CLIP`（越大越好）<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720171048.png)
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720171140.png)
### 二、 Generation Model<br>
这个就完全是`Diffusion Model`的操作<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720171408.png)
### 三、 Decoder<br>
这个很好理解，如果中间生成物是缩略图，那么放大就可以了<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720171239.png)
如果中间生成物是未知表示，如下图进行操作<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2023-7-6/20230720171255.png)
除了Decoder，你需要自己训练一个encoder，输入图片，输出是中间表示，把其输出放入Decoder，判断decoder是否能生成理想的图片<br>
