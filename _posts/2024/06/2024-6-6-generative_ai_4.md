---
layout: post
tags: [AI]
title: "generative-ai å­¦ä¹ ç¬”è®° â…£"
author: wsxk
comments: true
date: 2024-6-6
---

- [å‰è¨€](#å‰è¨€)
- [10. Building Low Code AI Applications](#10-building-low-code-ai-applications)
- [11. Integrating with function calling](#11-integrating-with-function-calling)
  - [11.1 Why Function Calling](#111-why-function-calling)
  - [11.2 Illustrating the problem through a scenario](#112-illustrating-the-problem-through-a-scenario)
  - [11.3 Use Cases for using function calls](#113-use-cases-for-using-function-calls)
  - [11.4 Integrating Function Calls into an Application](#114-integrating-function-calls-into-an-application)
- [12. Designing UX for AI Applications](#12-designing-ux-for-ai-applications)


## å‰è¨€<br>
è¯·çœ‹å®Œå‰é¢çš„ç« èŠ‚ï¼Œanywayå…¶å®ä½ ä¸çœ‹ä¹Ÿæ²¡ä»€ä¹ˆå¤§é—®é¢˜~<br>
ğŸ˜„<br>

## 10. Building Low Code AI Applications<br>
ç›®å‰è®¤è¯†çš„æ¥è§¦è¿‡æ‰€è°“ä½ä»£ç çš„æœ‹å‹éƒ½å¯¹å®ƒå—¤ä¹‹ä»¥é¼»ï¼Œè®©æˆ‘æ¥é‰´å®šä¸€ä¸‹ä»–çš„æˆåˆ†ï¼<br>
ç›®å‰æ¥çœ‹ï¼Œæ‰€è°“ä½ä»£ç ï¼ŒæŒ‡çš„æ˜¯**è®©ä½ ä¸éœ€è¦å¼€å‘ä»£ç ï¼Œæˆ–è€…ä½¿ç”¨å¾ˆå°‘çš„ä»£ç æ¥æ„å»ºåº”ç”¨ç¨‹åº**ï¼Œç±»ä¼¼äºå°‘å„¿ç¼–ç¨‹çš„é‚£ç§ä¸œè¥¿ï¼Œè®©ä½ é€šè¿‡æ‹–æ‹½æŸäº›ä»£è¡¨åŠŸèƒ½çš„ç§¯æœ¨ï¼Œæ¥æ­å»ºä½ æƒ³è¦çš„ç¨‹åºã€‚<br>
anywayï¼Œæˆ‘æ„Ÿè§‰è¿™å¥½åƒæ²¡ä»€ä¹ˆå¥½å­¦çš„ï¼Œpassã€‚<br>

## 11. Integrating with function calling<br>
### 11.1 Why Function Calling<br>
ç”¨å‡½æ•°è°ƒç”¨çš„æ–¹å¼æ¥é›†æˆ`AI`åŠŸèƒ½ï¼ˆanywayï¼Œå·²ç»è¯´äº†å¾ˆå¤šéäº†ï¼Œæ„Ÿè§‰è¿™ä¹Ÿæœ‰ç‚¹æ°´äº†ï¼‰ã€‚<br>
ä¼˜åŠ¿å¦‚ä¸‹ï¼š<br>
```
Consistent response format : ä¸€è‡´çš„å“åº”æ ¼å¼
å¦‚æœæˆ‘ä»¬å¯ä»¥æ›´å¥½çš„æ§åˆ¶å“åº”æ ¼å¼ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæ›´å®¹æ˜“çš„æŠŠå“åº”é›†æˆåˆ°ä¸‹æ¸¸çš„å…¶å®ƒç³»ç»Ÿä¸­ã€‚


External data : æ‹“å±•çš„æ•°æ®
å¯ä»¥åœ¨ä¸€ä¸ªå¯¹è¯ä¸­ï¼Œä½¿ç”¨æ¥è‡ªäºå…¶ä»–æ¥æºçš„æ•°æ®ï¼Œå¯ä»¥è§£å†³LLMè®­ç»ƒæ—¶æ•°æ®çš„æ—¶é—´é™åˆ¶
```

### 11.2 Illustrating the problem through a scenario<br>
è¯·çœ‹ç¤ºä¾‹ä»£ç :<br>
```python
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

student_1_description="Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating."
 
student_2_description = "Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies."

prompt1 = f'''
Please extract the following information from the given text and return it as a JSON object:

name
major
school
grades
club

This is the body of text to extract the information from:
{student_1_description}
'''


prompt2 = f'''
Please extract the following information from the given text and return it as a JSON object:

name
major
school
grades
club

This is the body of text to extract the information from:
{student_2_description}
'''

response1 = client.chat.completions.create(
    model=deployment, 
    messages=[{"role": "user", "content": prompt1}]
    )
print(response1.choices[0].message.content)

response2 = client.chat.completions.create(
    model=deployment,
    messages=[{"role": "user", "content": prompt2}]
    )
print(response2.choices[0].message.content)
```

ç»“æœå¦‚ä¸‹ï¼š<br>
```json
{
  "name": "Emily Johnson",
  "major": "computer science",
  "school": "Duke University",
  "grades": 3.7,
  "club": ["Chess Club", "Debate Team"]
}

{
  "name": "Michael Lee",
  "major": "computer science",
  "school": "Stanford University",
  "grades": "3.8 GPA",
  "club": "Robotics Club"
}
```
å³ä½¿promptæ˜¯ç›¸åŒçš„ï¼Œæè¿°ä¹Ÿå¾ˆç±»ä¼¼ï¼Œä½†æ˜¯gradesè¿™ä¸ªå˜é‡çš„å€¼å¹¶ä¸æ˜¯ä¸€æ ·çš„ã€‚<br>
**è¿™æ˜¯å› ä¸ºLLMä»¥å†™ä¸‹çš„promptçš„æ–¹å¼æ¥æå–éç»“æ„åŒ–çš„æ•°æ®ï¼Œå¹¶è¿”å›éç»“æ„åŒ–çš„æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªç»“æ„åŒ–çš„æ ¼å¼ï¼Œä»¥ä¾¿æˆ‘ä»¬çŸ¥é“å½“å­˜å‚¨æˆ–ä½¿ç”¨æ•°æ®æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆ**<br>
è¿™å°±æ˜¯è¦ç”¨`function calling`çš„åŸå› ã€‚<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2024-3-25/20240611230845.png)

### 11.3 Use Cases for using function calls<br>
æ€»ä¹‹ï¼Œä½¿ç”¨æ‰€è°“çš„`function calling`è¿˜æœ‰å…¶ä»–å¥½å¤„ï¼ˆæœ‰æ—¶å€™æˆ‘çœŸçš„æŒºä½©æœè€ç¾çš„ï¼Œèƒ½æƒ³è¿™ä¹ˆå¤šå¥‡è‘©å¥½å¤„<br>

```
Calling External Tools. ä½¿ç”¨æ‹“å±•å·¥å…· 
Chatbots are great at providing answers to questions from users. By using function calling, the chatbots can use messages from users to complete certain tasks. For example, a student can ask the chatbot to "Send email to my instructor saying I need more assistance with this subject". This can make a function call to send_email(to: string, body: string)

Create API or Database Queries.  åˆ›å»ºAPIæˆ–è€…æ•°æ®åº“æŸ¥è¯¢
Users can find information using natural language that gets converted into a formatted query or API request. An example of this could be a teacher who requests "Who are the students that completed the last assignment" which could call a function named get_completed(student_name: string, assignment: int, current_status: string)

Creating Structured Data.  åˆ›å»ºç»“æ„åŒ–æ•°æ®
Users can take a block of text or CSV and use the LLM to extract important information from it. For example, a student can convert a Wikipedia article about peace agreements to create AI flash cards. This can be done by using a function called get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)
```

åˆ›å»º`function call`æœ‰3ä¸ªä¸»è¦æ­¥éª¤<br>
```
1ã€Calling the Chat Completions API with a list of your functions and a user message.

2ã€Reading the model's response to perform an action ie execute a function or API Call.

3ã€Making another call to Chat Completions API with the response from your function to use that information to create a response to the user.

```
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2024-3-25/20240612230158.png)
å°å°çš„ä¸¾ä¸ªä¾‹å­ï¼š<br>
```python
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

# step 1 : creating messages
messages= [ {"role": "user", "content": "Find me a good course for a beginner student to learn Azure."} ]
# step 2 : creating functions
functions = [
   {
      "name":"search_courses",
      "description":"Retrieves courses from the search index based on the parameters provided",
      "parameters":{
         "type":"object",
         "properties":{
            "role":{
               "type":"string",
               "description":"The role of the learner (i.e. developer, data scientist, student, etc.)"
            },
            "product":{
               "type":"string",
               "description":"The product that the lesson is covering (i.e. Azure, Power BI, etc.)"
            },
            "level":{
               "type":"string",
               "description":"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)"
            }
         },
         "required":[
            "role"
         ]
      }
   }
]
# step 3 : Making the function call
response = client.chat.completions.create(model=deployment,
                                        messages=messages,
                                        functions=functions,
                                        function_call="auto")

print(response.choices[0].message)
```
ä¸ªäººæ„Ÿè§‰**creating functions**è¿™ä¸ªæ­¥éª¤å¾ˆç²¾é«“å•Š<br>
- `name` - The name of the function that we want to have called.
- `description` - This is the description of how the function works. Here it's important to be specific and clear.
- `parameters` - A list of values and format that you want the model to produce in its response. The parameters array consists of items where item have the following properties:
  1.  `type` - The data type of the properties will be stored in.
  1.  `properties` - List of the specific values that the model will use for its response
      1. `name` - The key is the name of the property that the model will use in its formatted response, for example, `product`.
      1. `type` - The data type of this property, for example, `string`.
      1. `description` - Description of the specific property.

There's also an optional property `required` - required property for the function call to be completed.

### 11.4 Integrating Function Calls into an Application<br>
ç›´æ¥çœ‹å®ä¾‹<br>
**è¿™ä¸ªå®ä¾‹å‘Šè¯‰æˆ‘ä»¬å¦‚ä½•è®©LLMå’Œfunction callè”åŠ¨èµ·æ¥ï¼Œååˆ†é«˜çº§**<br>

```python
import os
import json
import requests
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

# step 1 : creating messages
messages= [ {"role": "user", "content": "Find me a good course for a beginner student to learn Azure."} ]
# step 2 : creating functions
functions = [
   {
      "name":"search_courses",   # å‡½æ•°åç§°
      "description":"Retrieves courses from the search index based on the parameters provided", # å‡½æ•°åŠŸèƒ½æè¿°ï¼Œç®€ä»‹å‡†ç¡®
      "parameters":{   # å‡½æ•°å‚æ•°
         "type":"object", # å‚æ•°çš„ç±»å‹ï¼Œä¸ºobjectï¼Œå³å­—å…¸
         "properties":{   # å‚æ•°çš„å±æ€§æœ‰å“ªäº›ï¼Œå³å­—å…¸ä¸­åŒ…å«å“ªäº›å±æ€§
            "role":{     # å±æ€§åç§°
               "type":"string", # å±æ€§ç±»å‹
               "description":"The role of the learner (i.e. developer, data scientist, student, etc.)" # å±æ€§æè¿°
            },
            "product":{
               "type":"string",
               "description":"The product that the lesson is covering (i.e. Azure, Power BI, etc.)"
            },
            "level":{
               "type":"string",
               "description":"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)"
            }
         },
         "required":[  # å¿…é¡»å‚æ•°ï¼Œå³å‚æ•°ä¸­å¿…é¡»åŒ…å«çš„å±æ€§åç§°
            "role"
         ]
      }
   }
]
# step 3 : Making the function call
response = client.chat.completions.create(model=deployment,
                                        messages=messages,
                                        functions=functions,  # æŠŠå‡½æ•°æè¿°æ”¾å…¥è¿™é‡Œï¼Œå¯¹äºLLMæ¥è¯´ï¼Œè¿™å°±æ˜¯å¯è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
                                        function_call="auto") # è®©LLMå†³å®šä½•æ—¶è°ƒç”¨å‡½æ•°
print("response_message:")
print(response.choices[0].message)
print()

response_message = response.choices[0].message

def search_courses(role, product, level):   # å‡½æ•°çš„å®é™…å®ç°
   url = "https://learn.microsoft.com/api/catalog/"   # ä»ç›®æ ‡apiè·å–æ•°æ®
   params = {
      "role": role,
      "product": product,
      "level": level
   }
   response = requests.get(url, params=params)
   modules = response.json()["modules"]
   results = []
   for module in modules[:5]:
      title = module["title"]
      url = module["url"]
      results.append({"title": title, "url": url})
   return str(results)

# Check if the model wants to call a function
if response_message.function_call.name:  # è¿™é‡Œåœ¨è¿”å›å€¼ä¼šå‘Šè¯‰ä½ è¦è°ƒç”¨å‡½æ•°
   print("Recommended Function call:")
   print(response_message.function_call.name)  # æ‰“å°è¦è°ƒç”¨çš„å‡½æ•°åç§°
   print()

   # Call the function.
   function_name = response_message.function_call.name

   available_functions = {
            "search_courses": search_courses,
   }
   function_to_call = available_functions[function_name]  

   function_args = json.loads(response_message.function_call.arguments)
   print("function_args:")
   print(function_args)
   print()
   function_response = function_to_call(**function_args) # å®é™…æ ¹æ®å‡½æ•°åç§°ï¼Œè°ƒç”¨äº†çœŸçš„å‡½æ•°ï¼Œ**åœ¨è¿™é‡Œçš„ä½œç”¨æ˜¯å°†ä¸€ä¸ªå­—å…¸å±•å¼€ä¸ºå…³é”®å­—å‚æ•°ï¼ˆkeyword argumentsï¼‰

   print("Output of function call:")
   print(function_response)
   print(type(function_response))
   print()


   # Add the assistant response and function response to the messages
   messages.append( # adding assistant response to messages
      {
            "role": response_message.role,
            "function_call": {
               "name": function_name,
               "arguments": response_message.function_call.arguments,
            },
            "content": None
      }
   )
   messages.append( # adding function response to messages
      {
            "role": "function",
            "name": function_name,
            "content":function_response,
      }
   )

print("Messages in next request:")
print(messages)
print()

second_response = client.chat.completions.create(
   messages=messages,
   model=deployment,
   function_call="auto",
   functions=functions,
   temperature=0
      )  # get a new response from GPT where it can see the function response

print(second_response.choices[0].message.content)
```

## 12. Designing UX for AI Applications<br>
æœ¬èŠ‚å¯ä»¥ç®€å•æ¦‚è¿°ä¸ºï¼Œ**åŸºäºç”¨æˆ·ä½“éªŒå’Œç”¨æˆ·éœ€è¦ï¼ŒåŸºäºåˆä½œå’Œåé¦ˆæœºåˆ¶ï¼Œæ„å»ºå¯ä¿¡é€æ˜çš„aiåº”ç”¨ã€‚**<br>
