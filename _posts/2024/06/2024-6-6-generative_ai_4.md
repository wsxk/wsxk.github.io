---
layout: post
tags: [AI]
title: "generative-ai å­¦ä¹ ç¬”è®° â…£"
author: wsxk
comments: true
date: 2024-6-6
---

- [å‰è¨€](#å‰è¨€)
- [10. Building Low Code AI Applications](#10-building-low-code-ai-applications)
- [11. Integrating with function calling](#11-integrating-with-function-calling)
  - [11.1 Why Function Calling](#111-why-function-calling)
  - [11.2 Illustrating the problem through a scenario](#112-illustrating-the-problem-through-a-scenario)
  - [11.3 Use Cases for using function calls](#113-use-cases-for-using-function-calls)
  - [11.4 Integrating Function Calls into an Application](#114-integrating-function-calls-into-an-application)
- [12. Designing UX for AI Applications](#12-designing-ux-for-ai-applications)
  - [12.1 å½±å“UXçš„å› ç´ ](#121-å½±å“uxçš„å› ç´ )
- [13. Securing Your Generative AI Applications](#13-securing-your-generative-ai-applications)
  - [13.1 Understanding the threats and risks of AI](#131-understanding-the-threats-and-risks-of-ai)
  - [13.2 LLMSå’ŒAI systemsçš„å®‰å…¨æµ‹è¯•](#132-llmså’Œai-systemsçš„å®‰å…¨æµ‹è¯•)
  - [13.3 LLMSå’ŒAI systemsçš„ä¿æŠ¤è¦ç‚¹](#133-llmså’Œai-systemsçš„ä¿æŠ¤è¦ç‚¹)
- [14. The Generative AI Application Lifecycle](#14-the-generative-ai-application-lifecycle)


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-C22S5YSYL7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-C22S5YSYL7');
</script>

## å‰è¨€<br>
è¯·çœ‹å®Œå‰é¢çš„ç« èŠ‚ï¼Œanywayå…¶å®ä½ ä¸çœ‹ä¹Ÿæ²¡ä»€ä¹ˆå¤§é—®é¢˜~<br>
ğŸ˜„<br>

## 10. Building Low Code AI Applications<br>
ç›®å‰è®¤è¯†çš„æ¥è§¦è¿‡æ‰€è°“ä½ä»£ç çš„æœ‹å‹éƒ½å¯¹å®ƒå—¤ä¹‹ä»¥é¼»ï¼Œè®©æˆ‘æ¥é‰´å®šä¸€ä¸‹ä»–çš„æˆåˆ†ï¼<br>
ç›®å‰æ¥çœ‹ï¼Œæ‰€è°“ä½ä»£ç ï¼ŒæŒ‡çš„æ˜¯**è®©ä½ ä¸éœ€è¦å¼€å‘ä»£ç ï¼Œæˆ–è€…ä½¿ç”¨å¾ˆå°‘çš„ä»£ç æ¥æ„å»ºåº”ç”¨ç¨‹åº**ï¼Œç±»ä¼¼äºå°‘å„¿ç¼–ç¨‹çš„é‚£ç§ä¸œè¥¿ï¼Œè®©ä½ é€šè¿‡æ‹–æ‹½æŸäº›ä»£è¡¨åŠŸèƒ½çš„ç§¯æœ¨ï¼Œæ¥æ­å»ºä½ æƒ³è¦çš„ç¨‹åºã€‚<br>
anywayï¼Œæˆ‘æ„Ÿè§‰è¿™å¥½åƒæ²¡ä»€ä¹ˆå¥½å­¦çš„ï¼Œpassã€‚<br>

## 11. Integrating with function calling<br>
### 11.1 Why Function Calling<br>
ç”¨å‡½æ•°è°ƒç”¨çš„æ–¹å¼æ¥é›†æˆ`AI`åŠŸèƒ½ï¼ˆanywayï¼Œå·²ç»è¯´äº†å¾ˆå¤šéäº†ï¼Œæ„Ÿè§‰è¿™ä¹Ÿæœ‰ç‚¹æ°´äº†ï¼‰ã€‚<br>
ä¼˜åŠ¿å¦‚ä¸‹ï¼š<br>
```
Consistent response format : ä¸€è‡´çš„å“åº”æ ¼å¼
å¦‚æœæˆ‘ä»¬å¯ä»¥æ›´å¥½çš„æ§åˆ¶å“åº”æ ¼å¼ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæ›´å®¹æ˜“çš„æŠŠå“åº”é›†æˆåˆ°ä¸‹æ¸¸çš„å…¶å®ƒç³»ç»Ÿä¸­ã€‚


External data : æ‹“å±•çš„æ•°æ®
å¯ä»¥åœ¨ä¸€ä¸ªå¯¹è¯ä¸­ï¼Œä½¿ç”¨æ¥è‡ªäºå…¶ä»–æ¥æºçš„æ•°æ®ï¼Œå¯ä»¥è§£å†³LLMè®­ç»ƒæ—¶æ•°æ®çš„æ—¶é—´é™åˆ¶
```

### 11.2 Illustrating the problem through a scenario<br>
è¯·çœ‹ç¤ºä¾‹ä»£ç :<br>
```python
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

student_1_description="Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating."
 
student_2_description = "Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies."

prompt1 = f'''
Please extract the following information from the given text and return it as a JSON object:

name
major
school
grades
club

This is the body of text to extract the information from:
{student_1_description}
'''


prompt2 = f'''
Please extract the following information from the given text and return it as a JSON object:

name
major
school
grades
club

This is the body of text to extract the information from:
{student_2_description}
'''

response1 = client.chat.completions.create(
    model=deployment, 
    messages=[{"role": "user", "content": prompt1}]
    )
print(response1.choices[0].message.content)

response2 = client.chat.completions.create(
    model=deployment,
    messages=[{"role": "user", "content": prompt2}]
    )
print(response2.choices[0].message.content)
```

ç»“æœå¦‚ä¸‹ï¼š<br>
```json
{
  "name": "Emily Johnson",
  "major": "computer science",
  "school": "Duke University",
  "grades": 3.7,
  "club": ["Chess Club", "Debate Team"]
}

{
  "name": "Michael Lee",
  "major": "computer science",
  "school": "Stanford University",
  "grades": "3.8 GPA",
  "club": "Robotics Club"
}
```
å³ä½¿promptæ˜¯ç›¸åŒçš„ï¼Œæè¿°ä¹Ÿå¾ˆç±»ä¼¼ï¼Œä½†æ˜¯gradesè¿™ä¸ªå˜é‡çš„å€¼å¹¶ä¸æ˜¯ä¸€æ ·çš„ã€‚<br>
**è¿™æ˜¯å› ä¸ºLLMä»¥å†™ä¸‹çš„promptçš„æ–¹å¼æ¥æå–éç»“æ„åŒ–çš„æ•°æ®ï¼Œå¹¶è¿”å›éç»“æ„åŒ–çš„æ•°æ®ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦æœ‰ä¸€ä¸ªç»“æ„åŒ–çš„æ ¼å¼ï¼Œä»¥ä¾¿æˆ‘ä»¬çŸ¥é“å½“å­˜å‚¨æˆ–ä½¿ç”¨æ•°æ®æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆ**<br>
è¿™å°±æ˜¯è¦ç”¨`function calling`çš„åŸå› ã€‚<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2024-3-25/20240611230845.png)

### 11.3 Use Cases for using function calls<br>
æ€»ä¹‹ï¼Œä½¿ç”¨æ‰€è°“çš„`function calling`è¿˜æœ‰å…¶ä»–å¥½å¤„ï¼ˆæœ‰æ—¶å€™æˆ‘çœŸçš„æŒºä½©æœè€ç¾çš„ï¼Œèƒ½æƒ³è¿™ä¹ˆå¤šå¥‡è‘©å¥½å¤„<br>

```
Calling External Tools. ä½¿ç”¨æ‹“å±•å·¥å…· 
Chatbots are great at providing answers to questions from users. By using function calling, the chatbots can use messages from users to complete certain tasks. For example, a student can ask the chatbot to "Send email to my instructor saying I need more assistance with this subject". This can make a function call to send_email(to: string, body: string)

Create API or Database Queries.  åˆ›å»ºAPIæˆ–è€…æ•°æ®åº“æŸ¥è¯¢
Users can find information using natural language that gets converted into a formatted query or API request. An example of this could be a teacher who requests "Who are the students that completed the last assignment" which could call a function named get_completed(student_name: string, assignment: int, current_status: string)

Creating Structured Data.  åˆ›å»ºç»“æ„åŒ–æ•°æ®
Users can take a block of text or CSV and use the LLM to extract important information from it. For example, a student can convert a Wikipedia article about peace agreements to create AI flash cards. This can be done by using a function called get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)
```

åˆ›å»º`function call`æœ‰3ä¸ªä¸»è¦æ­¥éª¤<br>
```
1ã€Calling the Chat Completions API with a list of your functions and a user message.

2ã€Reading the model's response to perform an action ie execute a function or API Call.

3ã€Making another call to Chat Completions API with the response from your function to use that information to create a response to the user.

```
å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br>
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2024-3-25/20240612230158.png)
å°å°çš„ä¸¾ä¸ªä¾‹å­ï¼š<br>
```python
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

# step 1 : creating messages
messages= [ {"role": "user", "content": "Find me a good course for a beginner student to learn Azure."} ]
# step 2 : creating functions
functions = [
   {
      "name":"search_courses",
      "description":"Retrieves courses from the search index based on the parameters provided",
      "parameters":{
         "type":"object",
         "properties":{
            "role":{
               "type":"string",
               "description":"The role of the learner (i.e. developer, data scientist, student, etc.)"
            },
            "product":{
               "type":"string",
               "description":"The product that the lesson is covering (i.e. Azure, Power BI, etc.)"
            },
            "level":{
               "type":"string",
               "description":"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)"
            }
         },
         "required":[
            "role"
         ]
      }
   }
]
# step 3 : Making the function call
response = client.chat.completions.create(model=deployment,
                                        messages=messages,
                                        functions=functions,
                                        function_call="auto")

print(response.choices[0].message)
```
ä¸ªäººæ„Ÿè§‰**creating functions**è¿™ä¸ªæ­¥éª¤å¾ˆç²¾é«“å•Š<br>
- `name` - The name of the function that we want to have called.
- `description` - This is the description of how the function works. Here it's important to be specific and clear.
- `parameters` - A list of values and format that you want the model to produce in its response. The parameters array consists of items where item have the following properties:
  1.  `type` - The data type of the properties will be stored in.
  1.  `properties` - List of the specific values that the model will use for its response
      1. `name` - The key is the name of the property that the model will use in its formatted response, for example, `product`.
      1. `type` - The data type of this property, for example, `string`.
      1. `description` - Description of the specific property.

There's also an optional property `required` - required property for the function call to be completed.

### 11.4 Integrating Function Calls into an Application<br>
ç›´æ¥çœ‹å®ä¾‹<br>
**è¿™ä¸ªå®ä¾‹å‘Šè¯‰æˆ‘ä»¬å¦‚ä½•è®©LLMå’Œfunction callè”åŠ¨èµ·æ¥ï¼Œååˆ†é«˜çº§**<br>

```python
import os
import json
import requests
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

client = OpenAI()
deployment = "gpt-3.5-turbo"

# step 1 : creating messages
messages= [ {"role": "user", "content": "Find me a good course for a beginner student to learn Azure."} ]
# step 2 : creating functions
functions = [
   {
      "name":"search_courses",   # å‡½æ•°åç§°
      "description":"Retrieves courses from the search index based on the parameters provided", # å‡½æ•°åŠŸèƒ½æè¿°ï¼Œç®€ä»‹å‡†ç¡®
      "parameters":{   # å‡½æ•°å‚æ•°
         "type":"object", # å‚æ•°çš„ç±»å‹ï¼Œä¸ºobjectï¼Œå³å­—å…¸
         "properties":{   # å‚æ•°çš„å±æ€§æœ‰å“ªäº›ï¼Œå³å­—å…¸ä¸­åŒ…å«å“ªäº›å±æ€§
            "role":{     # å±æ€§åç§°
               "type":"string", # å±æ€§ç±»å‹
               "description":"The role of the learner (i.e. developer, data scientist, student, etc.)" # å±æ€§æè¿°
            },
            "product":{
               "type":"string",
               "description":"The product that the lesson is covering (i.e. Azure, Power BI, etc.)"
            },
            "level":{
               "type":"string",
               "description":"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)"
            }
         },
         "required":[  # å¿…é¡»å‚æ•°ï¼Œå³å‚æ•°ä¸­å¿…é¡»åŒ…å«çš„å±æ€§åç§°
            "role"
         ]
      }
   }
]
# step 3 : Making the function call
response = client.chat.completions.create(model=deployment,
                                        messages=messages,
                                        functions=functions,  # æŠŠå‡½æ•°æè¿°æ”¾å…¥è¿™é‡Œï¼Œå¯¹äºLLMæ¥è¯´ï¼Œè¿™å°±æ˜¯å¯è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
                                        function_call="auto") # è®©LLMå†³å®šä½•æ—¶è°ƒç”¨å‡½æ•°
print("response_message:")
print(response.choices[0].message)
print()

response_message = response.choices[0].message

def search_courses(role, product, level):   # å‡½æ•°çš„å®é™…å®ç°
   url = "https://learn.microsoft.com/api/catalog/"   # ä»ç›®æ ‡apiè·å–æ•°æ®
   params = {
      "role": role,
      "product": product,
      "level": level
   }
   response = requests.get(url, params=params)
   modules = response.json()["modules"]
   results = []
   for module in modules[:5]:
      title = module["title"]
      url = module["url"]
      results.append({"title": title, "url": url})
   return str(results)

# Check if the model wants to call a function
if response_message.function_call.name:  # è¿™é‡Œåœ¨è¿”å›å€¼ä¼šå‘Šè¯‰ä½ è¦è°ƒç”¨å‡½æ•°
   print("Recommended Function call:")
   print(response_message.function_call.name)  # æ‰“å°è¦è°ƒç”¨çš„å‡½æ•°åç§°
   print()

   # Call the function.
   function_name = response_message.function_call.name

   available_functions = {
            "search_courses": search_courses,
   }
   function_to_call = available_functions[function_name]  

   function_args = json.loads(response_message.function_call.arguments)
   print("function_args:")
   print(function_args)
   print()
   function_response = function_to_call(**function_args) # å®é™…æ ¹æ®å‡½æ•°åç§°ï¼Œè°ƒç”¨äº†çœŸçš„å‡½æ•°ï¼Œ**åœ¨è¿™é‡Œçš„ä½œç”¨æ˜¯å°†ä¸€ä¸ªå­—å…¸å±•å¼€ä¸ºå…³é”®å­—å‚æ•°ï¼ˆkeyword argumentsï¼‰

   print("Output of function call:")
   print(function_response)
   print(type(function_response))
   print()


   # Add the assistant response and function response to the messages
   messages.append( # adding assistant response to messages
      {
            "role": response_message.role,
            "function_call": {
               "name": function_name,
               "arguments": response_message.function_call.arguments,
            },
            "content": None
      }
   )
   messages.append( # adding function response to messages
      {
            "role": "function",
            "name": function_name,
            "content":function_response,
      }
   )

print("Messages in next request:")
print(messages)
print()

second_response = client.chat.completions.create(
   messages=messages,
   model=deployment,
   function_call="auto",
   functions=functions,
   temperature=0
      )  # get a new response from GPT where it can see the function response

print(second_response.choices[0].message.content)
```

## 12. Designing UX for AI Applications<br>
æœ¬èŠ‚å¯ä»¥ç®€å•æ¦‚è¿°ä¸ºï¼Œ**åŸºäºç”¨æˆ·ä½“éªŒå’Œç”¨æˆ·éœ€è¦ï¼ŒåŸºäºåˆä½œå’Œåé¦ˆæœºåˆ¶ï¼Œæ„å»ºå¯ä¿¡é€æ˜çš„aiåº”ç”¨ã€‚**<br>
### 12.1 å½±å“UXçš„å› ç´ 
![](https://raw.githubusercontent.com/wsxk/wsxk_pictures/main/2024-3-25/20240616163718.png)

```
æœ‰ä»·å€¼(éœ€æ±‚å’Œå¸‚åœº)ï¼šé¦–è¦çš„ä¸€ç‚¹æ˜¯ï¼Œäº§å“å¿…é¡»æä¾›ä»·å€¼ã€‚ åœ¨æ—¶åˆ»è€ƒè™‘åˆ°ä»·å€¼å› ç´ çš„åŒæ—¶ï¼Œä½ éœ€è¦ç¡®è®¤æ­£åœ¨æ„å»ºçš„äº§å“ç¡®å®æœ‰éœ€æ±‚å’Œå¸‚åœºï¼Œå¹¶ä¸”äº§å“åœ¨ç›¸å…³å¸‚åœºå¾ˆå¯èƒ½ä¼šæˆåŠŸã€‚

æœ‰ç”¨(è™½ç„¶ä¸»è§‚ï¼Œä½†å¿…é¡»è€ƒè™‘)ï¼š
ä»ç”¨æˆ·è§’åº¦çœ‹ï¼Œä»–ä»¬å…³å¿ƒçš„æ˜¯â€œæ­¤äº§å“æœ‰ä½•åŠŸç”¨ï¼Ÿâ€è™½ç„¶äº§å“å¯¹ç”¨æˆ·æ˜¯å¦æœ‰ç”¨æ˜¯ä¸»è§‚çš„ï¼Œä½†ä½ ä»å¸Œæœ›æä¾›çš„äº§å“ä¸ç«äº‰å¯¹æ‰‹çš„ç›¸æ¯”å…·æœ‰æ›´é«˜çš„é‡è¦æ€§ã€‚

å¯ç”¨(ç”¨æˆ·èƒ½ç”¨)ï¼š
å¯ç”¨æ€§å†³å®šäº†ç”¨æˆ·ä½¿ç”¨äº§å“æ—¶çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚ ä»åˆ›å§‹äººçš„è§’åº¦çœ‹ï¼Œä½ å¸Œæœ›åˆ›å»ºä¸€ä¸ªä»¥æ»¡è¶³ç”¨æˆ·æœ€ç»ˆç›®æ ‡ä¸ºå®—æ—¨çš„è§£å†³æ–¹æ¡ˆã€‚

å¯æŸ¥æ‰¾(æ›å…‰åº¦è¦é«˜)ï¼š
åœ¨æ•°å­—åª’ä½“å’Œä¿¡æ¯ä¸°å¯Œçš„æ—¶ä»£ï¼Œä½ çš„äº§å“å¿…é¡»è¦èƒ½å¤Ÿå¾ˆå®¹æ˜“è¢«å‘ç°ã€‚
äº§å“å†…å®¹ä¹Ÿå¿…é¡»éšæ—¶å¯å‘ç°ã€‚ æ¢å¥è¯è¯´ï¼Œå¦‚æœç”¨æˆ·éƒ½æ‰¾ä¸åˆ°è¯¥äº§å“ï¼Œé‚£å°±æ›´éš¾è¯´è¦è´­ä¹°å’Œä½¿ç”¨è¯¥äº§å“äº†ã€‚

å¯ä¿¡èµ–(ä¿¡ä»»)ï¼š
æ— è®ºæ˜¯é€šè¿‡å£ç¢‘ã€ç›¸å…³æ€§è¿˜æ˜¯è¯„è®ºï¼Œç”¨æˆ·éƒ½å¸Œæœ›èƒ½å¤Ÿç¡®è®¤ä½ çš„äº§å“ä»–ä»¬ä¸ä»…èƒ½ç”¨è€Œä¸”èƒ½æœ‰æ•ˆæ»¡è¶³å…¶éœ€è¦ã€‚ 
å½“ä½ èƒ½å¤Ÿåœ¨è¯šå®å’Œä¸ºç”¨æˆ·ç€æƒ³çš„åŸºç¡€ä¸Šäº¤ä»˜æœ‰æ„ä¹‰çš„äº§å“æ—¶ï¼Œä½ å°±èƒ½èµ¢å¾—ç”¨æˆ·çš„ä¿¡ä»»ã€‚

æœ‰å¸å¼•åŠ›(é­…åŠ›)ï¼š
ç”±äºå¸‚åœºä¸Šæœ‰å¤§é‡çš„è§£å†³æ–¹æ¡ˆå’Œäº§å“ï¼Œä½ å¿…é¡»è®©è‡ªå·±çš„äº§å“èƒ½å¤Ÿä¸å…¶ä»–äº§å“ç›¸åŒºåˆ†ã€‚ 
åœ¨è®¾è®¡å’Œ UX æ–¹é¢ï¼Œå¿…é¡»è¦åœ¨æ›´å…·è¾…åŠ©æ€§çš„äº§å“ç»„æˆä¸­æŠ•å…¥æ—¶é—´å’Œç²¾åŠ›ï¼Œä¾‹å¦‚å“ç‰Œæ‰“é€ ã€èµ„äº§å’Œæ•´ä½“ç¾å­¦ã€‚ 
ç®€å•è€Œè¨€ï¼Œä½ çš„äº§å“è¶Šæœ‰å¸å¼•åŠ›ï¼Œç”¨æˆ·å°±è¶Šå€¾å‘äºä½¿ç”¨ä½ çš„äº§å“ã€‚

æ˜“äºä½¿ç”¨ï¼š
æ‹¥æœ‰å®Œç¾è®¾è®¡çš„æ¯ä¸€ä¸ªäº§å“éƒ½åº”èƒ½æä¾›èƒ½æ»¡è¶³å„ç•Œäººå£«çš„ä½“éªŒã€‚ 
ä½ ä¸å¸Œæœ›å¿½è§†ç”¨æˆ·ä½“éªŒä¸­çš„è¾…åŠ©åŠŸèƒ½ã€‚ 
UX æœ¯è¯­ä¸­çš„è¾…åŠ©åŠŸèƒ½æ„å‘³ç€ç”¨æˆ·ä½“éªŒèƒ½å¤Ÿé€‚åˆä¸åŒèƒ½åŠ›ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºæ®‹éšœäººå£«ï¼‰çš„ç”¨æˆ·ã€‚
```

## 13. Securing Your Generative AI Applications<br>
å°±æ˜¯aiçš„å®‰å…¨æ€§å¾ˆé‡è¦ï¼Œæ ¸å¿ƒçš„æ€è€ƒç‚¹æœ‰3ä¸ªï¼š<br>
```
1. Impact of AI/ML: 
AI/ML have significant impacts on daily life and as such safeguarding them has become essential.

2. Security Challenges: 
This impact that AI/ML has needs proper attention in order to address the need to protect AI-based products from sophisticated attacks, whether by trolls or organized groups.

3. Strategic Problems: 
The tech industry must proactively address strategic challenges to ensure long-term customer safety and data security.
```

### 13.1 Understanding the threats and risks of AI<br>
æ¥ä¸‹æ¥å…·ä½“AIæœ‰å“ªäº›å¨èƒå’Œé£é™©ï¼š<br>
```
1. Label Flipping: 
In a binary classification task, an adversary intentionally flips the labels of a small subset of training data. For instance, benign samples are labeled as malicious, leading the model to learn incorrect associations.

Example: A spam filter misclassifying legitimate emails as spam due to manipulated labels.

2. Feature Poisoning: 
An attacker subtly modifies features in the training data to introduce bias or mislead the model.

Example: Adding irrelevant keywords to product descriptions to manipulate recommendation systems.

3. Data Injection: 
Injecting malicious data into the training set to influence the modelâ€™s behavior.

Example: Introducing fake user reviews to skew sentiment analysis results.

4. Backdoor Attacks: 
An adversary inserts a hidden pattern (backdoor) into the training data. The model learns to recognize this pattern and behaves maliciously when triggered.

Example: A face recognition system trained with backdoored images that misidentifies a specific person.
```
å…¶å®æ•´äº†åŠå¤©ï¼Œéƒ½åªæ˜¯å¯¹è®­ç»ƒæ•°æ®é›†åšæ‰‹è„šï¼ŒåŒºåˆ«åœ¨äºå¯¹è®­ç»ƒé›†å“ªéƒ¨åˆ†æ•°æ®åšæ‰‹è„šç½¢äº†
å¦å¤–[The MITRE CorporationåŸºäºATT&CKåšäº†AIæ”»å‡»æ¨¡å¼åº“ ATLAS](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst)è¿™ä¸ªé“¾æ¥é‡Œé™äº†AIçš„å…¨éƒ¨é£é™©...<br>
å¦å¤–ï¼Œ**OWASP**æŠŠ**Prompt Injectionã€Supply Chain Vulnerabilitiesã€Overreliance**åˆ—ä¸ºAIçš„é‡è¦é£é™©<br>

### 13.2 LLMSå’ŒAI systemsçš„å®‰å…¨æµ‹è¯•<br>
æ¶µç›–é‡è¦çš„æµ‹è¯•æ–¹æ³•ï¼š
```
1. Data sanitization: 
è¿™æ˜¯ä»è®­ç»ƒæ•°æ®æˆ– AI ç³»ç»Ÿæˆ– LLM çš„è¾“å…¥ä¸­åˆ é™¤æˆ–åŒ¿ååŒ–æ•æ„Ÿæˆ–ç§äººä¿¡æ¯çš„è¿‡ç¨‹ã€‚æ•°æ®æ¸…ç†å¯ä»¥é€šè¿‡å‡å°‘æœºå¯†æˆ–ä¸ªäººæ•°æ®çš„æš´éœ²æ¥å¸®åŠ©é˜²æ­¢æ•°æ®æ³„éœ²å’Œæ¶æ„æ“çºµã€‚

2. Adversarial testing: 
è¿™æ˜¯ç”Ÿæˆå¯¹æŠ—æ€§ç¤ºä¾‹å¹¶å°†å…¶åº”ç”¨äº AI ç³»ç»Ÿæˆ– LLM çš„è¾“å…¥æˆ–è¾“å‡ºçš„è¿‡ç¨‹ï¼Œä»¥è¯„ä¼°å…¶å¯¹å¯¹æŠ—æ€§æ”»å‡»çš„ç¨³å¥æ€§å’Œå¼¹æ€§ã€‚å¯¹æŠ—æ€§æµ‹è¯•å¯ä»¥å¸®åŠ©è¯†åˆ«å’Œå‡è½»å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨çš„ AI ç³»ç»Ÿæˆ– LLM çš„æ¼æ´å’Œå¼±ç‚¹ã€‚

3. Model verification: 
è¿™æ˜¯éªŒè¯ AI ç³»ç»Ÿæˆ– LLM çš„æ¨¡å‹å‚æ•°æˆ–æ¶æ„çš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§çš„è¿‡ç¨‹ã€‚æ¨¡å‹éªŒè¯å¯ä»¥é€šè¿‡ç¡®ä¿æ¨¡å‹å—åˆ°ä¿æŠ¤å’Œè®¤è¯æ¥å¸®åŠ©æ£€æµ‹å’Œé˜²æ­¢æ¨¡å‹çªƒå–ã€‚

4. Output validation: 
è¿™æ˜¯éªŒè¯ AI ç³»ç»Ÿæˆ– LLM è¾“å‡ºè´¨é‡å’Œå¯é æ€§çš„è¿‡ç¨‹ã€‚è¾“å‡ºéªŒè¯å¯é€šè¿‡ç¡®ä¿è¾“å‡ºä¸€è‡´ä¸”å‡†ç¡®æ¥å¸®åŠ©æ£€æµ‹å’Œçº æ­£æ¶æ„æ“çºµã€‚

5. Emulating real-world threats - AI red teaming:
é€šè¿‡ä½¿ç”¨ç±»ä¼¼çš„å·¥å…·ã€ç­–ç•¥å’Œç¨‹åºæ¥è¯†åˆ«ç³»ç»Ÿé£é™©å¹¶æµ‹è¯•é˜²å¾¡è€…çš„ååº”ï¼Œæ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„å¨èƒç°åœ¨è¢«è®¤ä¸ºæ˜¯æ„å»ºå¼¹æ€§äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ ‡å‡†åšæ³•ã€‚
```
[https://github.com/openai/evals/tree/main](https://github.com/openai/evals/tree/main)è¿™ä¸ªç½‘å€é‡Œè¿˜æœ‰openaiæä¾›çš„ç”¨äºéªŒè¯æ¨¡å‹å®‰å…¨æ€§çš„æ•°æ®é›†~<br>


### 13.3 LLMSå’ŒAI systemsçš„ä¿æŠ¤è¦ç‚¹<br>
```
1. æ¨¡å‹å’Œç®—æ³•
2. aiå®‰å…¨ï¼šå³æ¨¡å‹çš„åè§ã€æ­§è§†ã€é“å¾·é—®é¢˜è¦å°‘ï¼›å†³ç­–æ—¶çš„å¯é—®è´£æ€§ã€é€æ˜åº¦å’Œå¯è§£é‡Šæ€§è¦é«˜
3ã€ç”¨æˆ·éšç§æ•°æ®
```

## 14. The Generative AI Application Lifecycle<br>
ä¸ªäººæ„Ÿè§‰æ²¡ç”¨ï¼Œpass<br>

