---
layout: post
tags: [AI]
title: "generative-ai å­¦ä¹ ç¬”è®° â…¢"
author: wsxk
comments: true
date: 2024-5-24
---

- [å‰è¨€](#å‰è¨€)
- [8. Building Search Applications](#8-building-search-applications)
  - [8.1 what is semantic search](#81-what-is-semantic-search)
  - [8.2 what are Text Embeddings](#82-what-are-text-embeddings)
  - [8.3 How is the Embedding index created?](#83-how-is-the-embedding-index-created)
  - [8.4 how to search?](#84-how-to-search)
  - [8.5 å®ä¾‹](#85-å®ä¾‹)
- [9. Building  Image Applications](#9-building--image-applications)
  - [9.1 What is DALL-E and Midjourney?](#91-what-is-dall-e-and-midjourney)
  - [æ’æ›²: tokenizationå’Œtext embedding](#æ’æ›²-tokenizationå’Œtext-embedding)
  - [9.2 How does DALL-E and Midjourney Work](#92-how-does-dall-e-and-midjourney-work)
  - [9.3 instance](#93-instance)

## å‰è¨€<br>
æ¬¢è¿åœ¨é˜…è¯»æœ¬ç¯‡ä¹‹å‰ï¼Œé˜…è¯»[generative-ai å­¦ä¹ ç¬”è®° â…¡](https://wsxk.github.io/generative_ai_2/)<br>

## 8. Building Search Applications<br>
æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¼šå­¦ä¹ :<br>
```
1. Semantic vs Keyword search
äº†è§£è¯­ä¹‰æœç´¢å’Œå…³é”®è¯æœç´¢çš„å·®åˆ«

2. What are Text Embeddings
Text Embeddings(vector) æ˜¯ä»€ä¹ˆï¼Œæœ‰ä»€ä¹ˆç”¨

3. Creating a Text Embeddings Index. Searching a Text Embeddings Index.
å¦‚ä½•åˆ›å»ºå’Œæœç´¢ Text Embeddings
```

### 8.1 what is semantic search<br>
`semantic search`å°±æ˜¯é‚£ç§ï¼Œä½ æœåˆ°`my dream car`ï¼Œå®ƒä¼šååº”è¿‡æ¥**æˆ‘æƒ³è¦æ‰¾çš„æ˜¯ideal car**ï¼Œè€Œä¸ä¼šåƒ`keyword search`é‚£æ ·ï¼Œä¼šéå†çš„æœå¯»**å…³äºè½¦çš„æ¢¦æƒ³**<br>

### 8.2 what are Text Embeddings<br>
`Text Embeddings`æ˜¯ä¸€ç§æŠŠæ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆè¯­ä¹‰çš„æ•°å­—è¡¨è¾¾ï¼‰çš„æŠ€æœ¯<br>
ä¸‹é¢æ˜¯ä¾‹å­:<br>
```
Today we are going to learn about Azure Machine Learning.

// å®é™…ä¸Švectoræœ‰å¾ˆå¤šï¼Œä¸ºäº†ç®€ä¾¿åªåˆ—äº†10ä¸ª
[-0.006655829958617687, 0.0026128944009542465, 0.008792596869170666, -0.02446001023054123, -0.008540431968867779, 0.022071078419685364, -0.010703742504119873, 0.003311325330287218, -0.011632772162556648, -0.02187200076878071, ...]
```

### 8.3 How is the Embedding index created?<br>
```
1. å°†å†…å®¹ä¸‹è½½ä¸‹æ¥ï¼Œæ¯”å¦‚ è§†é¢‘

2. ä½¿ç”¨openaiçš„åŠŸèƒ½ï¼Œä»å‰3åˆ†é’ŸæŠŠè§†é¢‘çš„ä½œè€…åç§°æå–å‡ºæ¥ï¼Œæ”¾å…¥vector databaseä¸­

3. å°†è§†é¢‘çš„æ–‡æœ¬åˆ‡åˆ†æˆ3minsçš„ç‰‡æ®µï¼Œä¸ºäº†ä¿è¯ç‰‡æ®µçš„å…³è”æ€§ï¼Œæ¯ä¸ªç‰‡æ®µéƒ½åŒ…å«å’Œä¸‹ä¸€ä¸ªç‰‡æ®µé‡åˆçš„20ä¸ªå•è¯

4. ä½¿ç”¨openai çš„apiåŠŸèƒ½ï¼ŒæŠŠæ¯ä¸ªæ–‡æœ¬ç‰‡æ®µè®©å¦‚å¹¶æå–å‡º60ä¸ªè¯å·¦å³çš„æ€»ç»“ï¼Œå°†æ€»ç»“æ”¾å…¥vector databaseä¸­

5. æœ€åï¼Œè¿˜æ˜¯ç”¨openaiçš„apiï¼ŒæŠŠæ¯ä¸ªæ–‡æœ¬å˜é‡çš„å‘é‡è¡¨è¾¾è®¡ç®—å‡ºæ¥ï¼Œæ”¾å…¥vector databaseä¸­
```
ä½¿ç”¨æ—¶ï¼Œæˆ‘ä»¬æœå¯»æŸä¸ª`å†…å®¹`ï¼Œè¿™ä¸ª`å†…å®¹`ä¼šå…ˆè¢«è½¬åŒ–ä¸º`vector`ï¼Œéšåå’Œæ•°æ®åº“ä¸­çš„`vector`åšæ¯”è¾ƒï¼Œæ‰¾åˆ°ç›¸ä¼¼çš„ï¼Œå¹¶å°†è¿™ä¸ª`vector`çš„æ–‡æœ¬æ€»ç»“ã€è§†é¢‘ä½œè€…åç§°å–å‡ºï¼Œå°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„æœç´¢å†…å®¹å•¦<br>

### 8.4 how to search?<br>
ä¸Šæ–‡æåˆ°çš„æœç´¢æŸä¸ªä¸œè¥¿,å…¶å®ç”¨åˆ°äº†**cosine similarity**çš„æŠ€æœ¯ï¼Œåœ¨æˆ‘ä»¬æœç´¢çš„`å†…å®¹`è¢«è½¬æ¢æˆ`vector`åï¼Œä¼šä¸`vector database`çš„å„ä¸ª`vector`è¿›è¡Œ**cosine similarity**çš„è®¡ç®—æ¥æ¯”å¯¹ç›¸ä¼¼åº¦ã€‚ç›¸ä¼¼åº¦é«˜çš„ä¼šè¢«å–å‡ºã€‚<br>

### 8.5 å®ä¾‹<br>
çœ‹äº†ä¸€ä¸ªæ¯”è¾ƒæœ‰è¶£çš„sample<br>
å†™æ³•å€¼å¾—å­¦ä¹ ï¼Œå¾ˆé«˜çº§ï¼ˆğŸ˜„<br>
```python
import os
import pandas as pd
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("OPENAI_API_KEY","")
assert API_KEY, "ERROR: OpenAI Key is missing"

client = OpenAI(
    api_key=API_KEY
    )

model = 'text-embedding-ada-002'

SIMILARITIES_RESULTS_THRESHOLD = 0.75
DATASET_NAME = "./08-building-search-applications/embedding_index_3m.json"


def load_dataset(source: str) -> pd.core.frame.DataFrame:
    # Load the video session index
    pd_vectors = pd.read_json(source)
    # for col in pd_vectors:
    #     print(col,end=": ")
    #     print(pd_vectors[col][0])
    return pd_vectors.drop(columns=["text"], errors="ignore").fillna("") # åˆ é™¤åä¸ºtextçš„åˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¿½ç•¥ï¼Œç¼ºçœå€¼ç”¨ç©ºå­—ç¬¦ä¸²å¡«å……

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)) # cosÎ¸ = aÂ·b / |a||b|

def get_videos(
    query: str, dataset: pd.core.frame.DataFrame, rows: int
) -> pd.core.frame.DataFrame:
    # create a copy of the dataset
    video_vectors = dataset.copy()

    # get the embeddings for the query    
    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding

    # create a new column with the calculated similarity for each row
    video_vectors["similarity"] = video_vectors["ada_v2"].apply(
        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))
    )

    # filter the videos by similarity
    mask = video_vectors["similarity"] >= SIMILARITIES_RESULTS_THRESHOLD
    # print(mask)
    video_vectors = video_vectors[mask].copy()
    # print(video_vectors)

    # sort the videos by similarity
    video_vectors = video_vectors.sort_values(by="similarity", ascending=False).head(
        rows
    )

    # return the top rows
    return video_vectors.head(rows)

def display_results(videos: pd.core.frame.DataFrame, query: str):
    def _gen_yt_url(video_id: str, seconds: int) -> str:
        """convert time in format 00:00:00 to seconds"""
        return f"https://youtu.be/{video_id}?t={seconds}"

    print(f"\nVideos similar to '{query}':")
    for _, row in videos.iterrows():
        print("_________________")
        print(_)
        print(row)
        print("_________________")
        youtube_url = _gen_yt_url(row["videoId"], row["seconds"])
        print(f" - {row['title']}")
        print(f"   Summary: {' '.join(row['summary'].split()[:15])}...")
        print(f"   YouTube: {youtube_url}")
        print(f"   Similarity: {row['similarity']}")
        print(f"   Speakers: {row['speaker']}")


pd_vectors = load_dataset(DATASET_NAME)


# get user query from imput
while True:
    query = input("Enter a query: ")
    if query == "exit":
        break
    videos = get_videos(query, pd_vectors, 5)
    display_results(videos, query)
```


## 9. Building  Image Applications<br>
å›¾åƒç”Ÿæˆè¿˜è›®é‡è¦çš„ï¼Œæœ‰å¾ˆå¤šçš„åº”ç”¨:<br>
> 1. Image editing and synthesis. 
> > å›¾åƒç¼–è¾‘å’Œåˆæˆå¯ä»¥ç”¨åˆ°
> 2. Applied to a variety of industries. 
> > å„ç§å„æ ·çš„è¡Œä¸šä¹Ÿèƒ½ç”¨åˆ°ï¼Œä¾‹å¦‚ï¼šåŒ»ç–—ç§‘æŠ€ã€æ—…æ¸¸ã€æ¸¸æˆå¼€å‘

### 9.1 What is DALL-E and Midjourney?<br>
`DALL-E`å’Œ`Midjourney`æ˜¯ä¸¤æ¬¾æ¯”è¾ƒè‘—åçš„å›¾ç‰‡ç”Ÿæˆå¤§æ¨¡å‹ã€‚<br>
å®ƒä»¬éƒ½å…è®¸ä½ ç”¨ç”¨æˆ·promptsç”Ÿæˆå›¾ç‰‡<br>
```
DALL-E

ç”±2ä¸ªéƒ¨åˆ†ç»„æˆï¼šCLIPå’Œ Diffused attention

CLIPæ˜¯ç”Ÿæˆembeddingçš„æ¨¡å‹ï¼Œå°†ç”¨æˆ·è¾“å…¥ï¼ˆå›¾ç‰‡å’Œæ–‡æœ¬ï¼‰è½¬æ¢ä¸ºembeddings

Diffused attentionç”¨äºè¯»å…¥embeddingsï¼Œè¾“å‡ºå›¾ç‰‡
```

`Midjourney`ä¸ä¹‹ç±»ä¼¼ï¼Œä¹Ÿèƒ½ç”Ÿæˆå›¾ç‰‡ã€‚<br>


### æ’æ›²: tokenizationå’Œtext embedding<br>
```
Tokenizationæ˜¯é¢„å¤„ç†é˜¶æ®µï¼Œç”¨äºå°†æ–‡æœ¬åˆ†è§£ä¸ºåŸºæœ¬å•å…ƒã€‚
Text Embeddingsæ˜¯ç‰¹å¾æå–é˜¶æ®µï¼Œç”¨äºå°†tokensè½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚
```

### 9.2 How does DALL-E and Midjourney Work<br>
å¯¹äº`DALL-E`è€Œè¨€<br>
```
DALL-E æ˜¯ä¸€ä¸ª Generative AI modelï¼Œ åŸºäº transformer æ¶æ„ï¼Œè¿˜å¸¦æœ‰ä¸€ä¸ª autoregressive transformer

autoregressive transformerå®šä¹‰äº†æ¨¡å‹å¦‚ä½•æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒï¼Œå®ƒä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªåƒç´ ï¼Œç„¶åä½¿ç”¨ç”Ÿæˆçš„åƒç´ ç”Ÿæˆä¸‹ä¸€ä¸ªåƒç´ ã€‚ç»è¿‡ç¥ç»ç½‘ç»œä¸­çš„å¤šå±‚ï¼Œç›´åˆ°å›¾åƒå®Œæ•´

é€šè¿‡æ­¤è¿‡ç¨‹ï¼ŒDALL-E å¯ä»¥æ§åˆ¶å…¶ç”Ÿæˆçš„å›¾åƒä¸­çš„å±æ€§ã€å¯¹è±¡ã€ç‰¹å¾ç­‰ã€‚ä½†æ˜¯ï¼ŒDALL-E 2 å’Œ 3 å¯¹ç”Ÿæˆçš„å›¾åƒçš„æ§åˆ¶æ›´å¼ºã€‚
```

### 9.3 instance<br>
æ¥ç‚¹å®ä¾‹ï¼š<br>
```python
from openai import OpenAI
import os
import requests
from PIL import Image
import dotenv
from io import BytesIO

# import dotenv
dotenv.load_dotenv()

 
client = OpenAI()


try:
    # Create an image by using the image generation API
    generation_response = client.images.generate(
        model="dall-e-3",
        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here
        size='1024x1024',
        n=1,
    )
    # Set the directory for the stored image
    image_dir = os.path.join(os.curdir, 'images')
    
    # If the directory doesn't exist, create it
    if not os.path.isdir(image_dir):
        os.mkdir(image_dir)
    print(image_dir)

    # Initialize the image path (note the filetype should be png)
    image_path = os.path.join(image_dir, 'generated-image.png')
    print(image_path)

    # Retrieve the generated image
    print(generation_response)

    image_url = generation_response.data[0].url # extract image URL from response
    generated_image = requests.get(image_url).content  # download the image
    with open(image_path, "wb") as image_file:
        image_file.write(generated_image)

    # Display the image in the default image viewer
    image = Image.open(image_path)
    image.show()

# catch exceptions
except client.error.InvalidRequestError as err:
    print(err)

# ---creating variation below---
response = client.images.create_variation(
  image=open(image_path, "rb"),
  n=1,
  size="1024x1024",
)
print(response)
image_url_variation = response.data[0].url
print(image_url_variation)
generated_image_variation = requests.get(image_url_variation).content
img = Image.open(BytesIO(generated_image_variation))
img.show()
```